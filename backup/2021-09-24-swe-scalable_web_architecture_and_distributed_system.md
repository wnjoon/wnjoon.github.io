---
layout: post
title:  "Scalable Web Architecture and Distributed Systems" 
excerpt: "Scalable Web Architecture and Distributed Systems - Kate Matsudaira의 내용을 학습한 후 이에 대한 내용을 정리한다."
date:   2021-09-24 15:00:00 +0900
categories: swe
tags: [system design, scalability, distributed system]
---

<br>

## 웹 분산 시스템 설계의 원리

확장 가능한 웹 사이트 또는 애플리케이션을 구축하고 운영한다는 것은, 기본적으로는 인터넷을 통해 원격의 리소스와 사용자를 연결하는 것이고 더 나아가 리소스 또는 해당 리소스에 접근할 수 있는 서버를 여러곳에 분산시켜 확장 가능하게 만드는 것을 말한다.  
대규모 웹 시스템 설계에 필요한 주요 원칙은 다음과 같다.
 
1. 가용성(Availability): 항상 시스템을 지속 가능하고 장애에 탄력적으로 설계해야 한다. 특히 분산환경에서의 고가용성을 위해 주요 구성요소의 중복, 부분적인 장애 발생에 대한 신속한 복구, 문제 발생에 대한 성능 저하 등을 고려해야 한다.
 
2. 성능(Performance): 빠른 응답과 짧은 대기 시간에 최적화 된 시스템을 적용해야 한다. 이는 사용자의 만족도 뿐만 아니라 검색 엔진 순위에도 영향을 준다.
 
3. 신뢰성(Reliability): 데이터 요청이 들어왔을 때, 항상 동일한 데이터를 일관되게 반환할 수 있어야 한다. 데이터가 변경되거나 업데이트되면, 동일한 요청에 대해  새로운 응답이 반환되어야 한다. 모든 사용자는 동일한 검색에 대해 동일한 결과값을 얻을 수 있어야 한다.
 
4. 확장성(Scalability): 더 많은 양의 데이터를 처리하기 위해 고민해야 하는 부분으로, 처리할 수 있는 추가 트래픽의 양과 스토리지의 양을 증가시키거나 처리할 수 있는 트랜잭션의 수를 증가하는 방식등이 있다. 확장에 대해 어느정도 고려하면서 설계한다면, 미래에 상당한 시간과 자원을 절약할 수 있다. 단, 필요하지도 않은 확장에 투자하는 것은 현명하지 못한 방안이 될 수 있다. 
 
5. 관리 용이성(Manageability): 운영하기 쉬운 시스템은 유지 관리 및 업데이트나 보수의 관점에서도 아주 용이하다. 문제가 발생할 때 어떻게 진단해야 하는지에 대한 이해가 쉬워야 하고, 업데이트 또는 수정이 용이하고 시스템 동작 방식이 단순해야 한다. 물론 실패나 예외 없이 동작해야 한다.
 
6. 비용(Cost): 하드웨어 및 소프트웨어 비용 뿐만 아니라, 시스템을 배포하고 유지 및 관리하는데 필요한 모든 측면에 대해 비용을 고려해야 한다. 여기에는 시스템을 구축하는데 필요한 개발자의 시간과 시스템을 실행하는데 필요한 운영 노력, 그리고 필요한 교육의 양까지도 모두 고려한다.

<br>

## 웹 이미지 호스팅 어플리케이션

많은 이미지를 호스팅하고 제공하는 대규모의 사이트를 설계한다고 가정하자. 효율적인 비용으로 높은 가용성과 검색시 짧은 대기시간을 갖는 시스템 설계가 필요할 것이다. 

![가장 단순화 한 이미지 호스팅 어플리케이션 아키텍처](http://www.aosabook.org/images/distsys/imageHosting1.jpg)  
*@그림 1: 가장 단순화 한 이미지 호스팅 어플리케이션 아키텍처*


쉬운 이해를 위해, 위의 시스템은 서버에 이미지를 업로드(쓰기)하는 기능과 쿼리(읽기)하는 기능만 있다고 가정하자. 
 
- 대부분의 이미지 호스팅은 읽기가 쓰기보다 더 빈번하게 발생하기 때문에, 빠른 이미지 조회가 가장 중요한 요소가 된다. 
- 이미지 다운로드 혹은 요청에 대해 낮은 지연시간이 필요하다.
- 저장되는 이미지 수에는 제한이 없어야 하며, 스토리지 확장성이 필요하다.
- 사용자는 존재하는 이미지에 대해서만 업로드가 가능하다(데이터 신뢰성).
- 유지관리가 쉬운 시스템이어야 한다.
- 높은 이윤이 없는 이미지 호스팅 특성상, 비용 효율적인 시스템이어야 한다.

### 1. 서비스(Services)

#### 1.1. 시스템 나누기

시스템을 확장하기 위한 설계를 할 때, 각 기능을 분리하고 시스템의 각 부분을 명확하게 정의된 인터페이스를 소유한 자체 서비스로 인식하면 도움이 된다. 이러한 방법을 SOA(Service-Oriented Architecture)라고 하는데, 각 서비스에 있는 고유한 컨텍스트는 API를 통해서만 외부와의 상호작용이 가능하다.  
위에서 우리는 시스템이 "읽기" 와 "쓰기"로 구성된다는 것을 알았다. 이미지의 업로드와 조회는 동시다발적으로 발생하기 때문에, 이 두가지 기능을 자체 서비스로 나누어 확장하는 것이 바람직하다. 대부분 다운로드와 업로드의 속도 비율은 3:1로 설정되는데, 일반적으로 읽는 과정은 캐시에서 일어나고 쓰기는 디스크로 이동하게 된다. [물론 캐시를 사용하지 않더라도 쓰기는 항상 읽기보다 느릴 수 밖에 없다](http://polepos.sourceforge.net/results/PolePositionClientServer.pdf).

![](http://www.aosabook.org/images/distsys/imageHosting2.png)  
*@그림 2: 읽기와 쓰기를 분리했을 때의 모습*

#### 1.2. 제한된 연결 수

아파치(Apache) 또는 lighttpd와 같은 웹 서버는 일반적으로 동시 연결 수에 제한선이 있다. 기본적으로 500명 + @ 인데, 트래픽이 많아질수록 연결 가능한 사용자 수가 비례하여 감소하게 된다. 특히 읽기의 경우 대부분 비동기적으로 동작하거나 gzip 압축 또는 대량 전송과 같이 성능 최적화를 위한 인코딩이 가능한것에 비해, 쓰기는 연결을 유지한 상태로 업로드하기 때문에 꼭 두 시스템 간 서버는 분리하는 것이 효율적이다.

> 아파치의 경우 최대 연결수를 500으로 설정할 경우, 초당 수천개의 읽기 요청이 가능하다.

#### 1.3. 나눔으로서 얻는 장점

서비스를 나눔으로써 얻을 수 있는 가장 큰 장점은 서로 독립적으로 동작하고, 이를 통해 독립적으로 문제 해결이 가능하다는 점이다. 다양한 방법을 통해 자체적으로 성능의 최적화가 가능하고, 각 서비스는 필요에 따라 독립적으로 확장 및 축소가 가능하다. 그리고 각 서비스는 서로 다른 상대 서비스에 영향을 주지 않게 된다. 

#### 1.4. 사례 - Flickr

Flickr는 하나의 서비스를 샤드로 나누고, 각 샤드가 정해진 수의 사용자만 처리할 수 있도록 샤드를 분산 구성하여 읽기/쓰기 문제를 해결한다. 그러므로 사용자가 증가할수록 샤드는 증가하는데, 위에서 살펴본 사용량 기준으로 하드웨어를 확장한 예시와 다르게 Flickr는 사용자 기반으로 이를 확인하기 때문에 확장 방식에 어려움이 있다. 
하지만 서비스 하나가 중단되거나 문제가 발생할 경우 위의 예시는 전체 시스템의 중단을 야기할 수 있지만, Flickr의 방식은 샤드에 포함된 특정 사용자에게만 문제가 발생되므로 지역적인 해결이 가능하다는 장점이 있다. 

### 2. 중복성(Redundancy)

실패가 발생하였을때, 단일 서버에 파일이 하나만 존재하게 되면 서버에 문제가 발생하였을 때 데이터의 손실이 일어나고 복구는 불가능하게 된다. 이를 방지하기 위해 복사본을 만들며, 웹 서비스에도 동일하게 적용된다.  
시스템에 중복성을 적용하면 위와 같이 단일실패점을 해결할 수 있다. 또한 서로 공유되지 않는 아키텍처를 구성함으로써 다른 노드에 대한 관리 없이 독립적인 운용이 가능하기 때문에 확장성을 쉽게 적용할 수 있다. 

![이중화를 적용한 이미지 호스팅 어플리케이션](http://www.aosabook.org/images/distsys/imageHosting3.png)  
*@그림 3: 이중화를 적용한 이미지 호스팅 어플리케이션*


### 3. 파티션(Partitions)

확장성은 크게 두가지 방식으로 구분된다.
 
- 수직확장: 개별 서버에 더 많은 리소스(CPU, 메모리 등)를 추가하는 방식
- 수평확장: 노드를 추가하는 방식(샤드, 파티션 등)

수평 확장 개념으로 보면, 만약 이미지를 저장하는 서버에 용량이 가득찰 경우 서버를 증가하면 된다. 단 어떤 이미지가 어떤 서버에 존재하는지를 매핑할 수 있는 체계가 필요하다. 이미지의 이름은 서버 전체에 적용되는 일관된 형태의 해싱 체계로 구현할 수 있다. 혹은 이미지 별로 ID를 부여하고 사용자로부터 요청이 왔을 때 해당 이미지를 매핑된 서버에서 조회할 수 있으면 된다.

![이중화 및 파티셔닝을 적용한 시스템](http://www.aosabook.org/images/distsys/imageHosting4.png)  
*@그림 4: 이중화 및 파티셔닝을 적용한 시스템*


하지만 이런 수평적인 확장에도 고려해야 할 문제점들은 분명히 존재할 수 있다.
 
- 데이터 지역성: 데이터 지역성은 여러 서버에 데이터나 기능을 배포할 때 발생 가능한 부분으로, 데이터를 요청하는 서버가 지역적으로 가까울수록 성능이 향상되고 멀수록 성능이 감소함으로써 발생한다.  
- 불일치: 철수가 데이터 A를 변경하고 있을 때, 영희가 해당 데이터를 접근한다고 가정하자. 데이터가 업데이트 되기 전에 이를 조회하는 경우, 불일치가 발생할 수 있다. 이렇게 되면 각 사용자 별로 같은 조회 서비스에 대한 다른 결과값을 얻을 수 있는 불일치가 발생하게 된다.

<br>

## 빠르고 확장성 있는 데이터 접근 방법

LAMP(Linux + Apache + Mysql/MariaDB + Perl/PHP/Python) 스택 어플리케이션과 같은 대부분의 웹 어플리케이션의 구조는 다음과 같다.

![LAMP 웹 어플리케이션 형태](http://www.aosabook.org/images/distsys/simpleWeb.png)  
*@그림 5: LAMP 웹 어플리케이션 형태*

뛰어난 확장성을 제공하려면 일반적으로 웹/앱 서버의 성능은 최소화되고 이를 수평적으로 확장하려는 시도를 보인다. 이렇게 되면 무거운 작업들은 어디에서 진행할 수 있을까? 대부분 데이터베이스 혹은 지원서버로 전달한다. 그리고 이곳에서 확장 과정중에 발생하는 대부분의 문제점이 발생할 수 있다.  
예시로 많은 테라바이트(TB)의 데이터가 존재하고, 사용자는 이 중 무작위로 한 데이터에 접근한다고 가정한다. 데이터는 메모리 혹은 디스크에 존재할 수 있는데, 접근 속도는 메모리가 디스크보다 월등히 빠르다.

![특정 데이터에 접근하는 경우](http://www.aosabook.org/images/distsys/accessingData.png)  
*@그림 6: 특정 데이터에 접근하는 경우*

> [메모리로 데이터에 접근할 경우, 디스크에서 읽는 것보다 순차읽기의 경우 6배, 무작위 읽기의 경우 100,000배 이상 빠르다.](https://queue.acm.org/detail.cfm?id=1563874)  

물론 아래의 다양한 방법을 이용하여 속도의 차이를 줄이고 빠르게 데이터에 접근할 수 있다.

### 1. 캐시(Caches)

캐시는 참조 지역성(locality of reference) 원칙을 사용한다. 이는 <u>'최근에 요청한 데이터가 빠른 시일 내에 다시 요청될 가능성이 높다'</u>는 전제를 둔다. 마치 단기 기억력과 비슷하다고 볼 수 있는데, 일반적인 데이터 접근보다 빠르며 가장 최근에 접근한 항목을 관리한다. 대개 프론트엔드 근처에서 사용되어, 백엔드에 부담을 주지 않고 빠르게 데이터를 조회하기 위해 사용된다.

![요청 계층 노드에 캐시 적용](http://www.aosabook.org/images/distsys/cache.png)  
*@그림 7: 요청 계층 노드에 캐시 적용*

캐시를 요청 계층 노드에 직접 적용하면 응답으로 반환된 데이터를 로컬에 저장할 수 있게 된다. 이렇게 되면 서비스 요청 시 로컬에서 빠르게 데이터 접근이 가능해진다. 만약 캐시에 데이터가 없으면 요청 노드는 디스크에서 데이터를 쿼리해서 가져온다. 물론 캐시는 요청 계층 노드 내에서도 메모리(빠름) 혹은 로컬 디스크(상대적으로 느리지만 네트워크에 접근하는 것 보다는 빠름) 모두에 위치할 수 있다.

![다중 캐시를 적용한 모습](http://www.aosabook.org/images/distsys/multipleCaches.png)  
*@그림 8: 다중 캐시를 적용한 모습*

문제는 이러한 요청 계층 노드를 여러 개로 분산할 때 발생한다. 가운데에서 로드밸런서(Load balancer)가 무작위로 데이터에 대한 요청을 분산하게 되면, 동일한 요청이 예상하지 못한 다른 노드로 이동하면서 지속적인 캐시 누락이 발생할 수 있다. 이를 방지하기 위한 방법으로 전역 캐시 혹은 분산 캐시 중 하나를 선택적으로 사용할 수 있다.

#### 1.1. 전역 캐시(Global Cache)

전역 캐시는 모든 노드가 동일한 단일 캐시 공간을 사용하는 방식이다. 기존의 저장소보다는 빠르면서 모든 요청 계층 노드에서 접근 가능한 서버 혹은 일종의 파일 스토리지를 별도의 캐시로 구성한다.  
단일 캐시로 구성되기 때문에 사용자에 의한 요청이 많아질수록 이를 잘 처리하기 위해 구성이 복잡해질 수 있다. 하지만 단일 캐시로 구성된 시스템이 굉장히 좋은 성능을 갖고 있거나, 혹은 데이터셋이 고정되어 있어서 접근 시간이 상대적으로 빠른 경우에는 좋은 선택지가 될 수 있다.

![캐시 누락에 대한 데이터 접근을 캐시가 직접하는 경우](http://www.aosabook.org/images/distsys/globalCache1.png)  
*@그림 9: 캐시 누락에 대한 데이터 접근을 캐시가 직접하는 경우*


![캐시 누락에 대한 데이터 요청을 요청계층노드에서 처리하는 경우](http://www.aosabook.org/images/distsys/globalCache2.png)  
*@그림 10: 캐시 누락에 대한 데이터 요청을 요청계층노드에서 처리하는 경우*

일반적으로는 캐시 누락이 발생할 경우, 캐시가 데이터 스토리지로 직접 검색하는 방식이 더 많이 사용된다. 이 방식의 장점은 캐시 자체가 검색을 관리하기 때문에, 수많은 요청자들에 의해 동일한 요청이 지속적으로 발생함으로써 일어날 수 있는 부하를 방지할 수 있다. 하지만 항상 이 방식이 옳은 것은 아니다. 만약 캐시 적중률이 낮아 누락이 계속해서 발생하게 되면, 캐시 버퍼가 캐시 누락으로 가득찰 수 있다.  
이러한 경우에는 캐시가 전체 데이터에 대한 대부분의 정보를 갖고 있고, 데이터 스토리지로의 요청을 요청 게층 노드가 분담하는 것이 더 좋은 방식이 된다. 혹은 캐시에 저장된 파일(내용)이 정적이고 제거되지 않는 경우에도 두번째 방식이 효과적일 수 있다.

#### 1.2. 분산 캐시(Distributed Cache)

분산 캐시는 쉽게 말해, 요청계층노드가 각자 캐시를 소유하고 있고 각 캐시들이 독립적으로 데이터 스토리지에 접근하여 캐시 누락에 대한 데이터를 조회하는 방식을 말한다. 

![분산 캐시 구성 모습](http://www.aosabook.org/images/distsys/distributedCaching.png)  
*@그림 11: 분산 캐시 구성 모습*

이러한 방식의 장점은 요청계층노드의 갯수만큼 캐시의 공간도 증가한다는 점이다. 하지만 요청계층노드를 삭제하거나 혹은 이를 수정하게 될 경우에는 복잡해질 수 있는데, 어차피 캐시 누락에 대한 요청은 모두가 동일하게 스토리지에 접근함으로써 해결되기 때문에 큰 문제점이라고 볼 수는 없다.

#### 1.3. 정리

다양한 방법이 존재하지만, 결국 캐시를 사용함으로써 얻을 수 있는 가장 큰 이점은 '작업을 훨씬 빠르게 할 수 있다'는 점이다. 하지만 대부분의 캐시는 메모리 형태로 구성되기 때문에, 그에 따른 값비싼 비용을 요구한다. 
가장 유명한 오픈소스 캐시는 [Memcached](http://memcached.org)로, 로컬 캐시와 분산 캐시 모두 적용 가능하도록 제공된다. 대부분의 대형 웹 사이트에서 사용되며, 일반적으로 O(1)의 빠른 데이터 저장 및 조회 성능을 제공하는 in-memory 형태의 key-value 저장소 형태를 갖는다. Facebook의 경우, Memcached를 사용하는 대표적인 회사로 알려져있다.

### 2. 프록시(Proxies)

프록시는 클라이언트로부터 요청을 받아 백엔드 서버로 이를 중계하는 하드웨어 혹은 소프트웨어 형태를 말한다. 일반적으로 요청을 필터링 또는 기록하거나 반환하는 경우에 사용되는데, 이 과정에서 헤더를 추가하거나 삭제할 수도 있고, 암호화 또는 복호화, 그리고 압축의 기능을 수행하기도 한다.

![프록시 서버 구조](http://www.aosabook.org/images/distsys/proxies.png)  
*@그림 12: 프록시 서버 구조*

#### 2.1. 축소 전달

프록시는 여러 서버로부터 요청을 받고 이를 조정할 때 유용하다. 시스템 전체 관점에서는 요청 트래픽을 최적화할 수 있는 방법을 제공하는데, 일반적으로 프록시를 이용하여 데이터 접근 속도를 높이기 위해 동일한(유사한) 요청을 하나의 요청으로 축소하고 이를 하나의 결과로 만들어서 클라이언트로 전달하는 '축소 전달(collapsed forwarding)' 방식을 사용한다.

![프록시 서버를 활용한 요청 축소 후 전달](http://www.aosabook.org/images/distsys/collapseRequests.png)  
*@그림 13: 프록시 서버를 활용한 요청 축소 후 전달*

만약 여러 노드로부터 동일한 데이터 요청이 들어왔는데, 해당 데이터가 캐시에 존재하지 않는다고 가정하자. 프록시가 이 요청을 받으면 프록시에서 디스크를 한번만 읽음으로써 문제를 해결할 수 있다. 물론 프록시로 이를 요청하는 대기시간이 더 높을 수도 있고, 이러한 유사한 요청을 그룹화하는데 걸리는 시간이 더 길 수도 있다. 하지만 동일한 데이터가 연속적으로 요청되는 경우에는 프록시를 이용하는 방식이 효과적이다. 한편으로는 캐시와 비슷해보이지만, 캐시처럼 데이터나 문서를 저장하지 않고도 해당 요청에 대한 호출을 최적화할 수 있다는 장점을 갖는다.

#### 2.2. 데이터 지역성 확대

프록시 사용을 통해 얻을 수 있는 또 다른 이점은 디스크(원본 저장소)로부터 지역(공간)적으로 가까운 위치에서 데이터를 요청할 수 있다는 것이다. 요청에 대한 데이터 지역성을 최대화하고 이를 통해 요청 대기 시간을 줄일 수 있다.  

![프록시를 활용한 데이터 요청에 대한 지역성 확대](http://www.aosabook.org/images/distsys/collapseRequestsSpatial.png)  
*@그림 14: 프록시를 활용한 데이터 요청에 대한 지역성 확대*

위의 그림을 예로 들면, 대다수의 노드가 B의 정보(partB1, partB2)를 요청한다고 하자. 프록시를 이용하여 해당 정보에 대한 지역성을 설정할 수 있고, 이러한 요청들을 하나로 모아서 단일 요청으로 축소한 후 B의 정보(bigB)만 반환하여 데이터 원본에 저장할 수 있다. 이렇게 하면 수많은 데이터에 무작위로 접근할 때 요청 시간에 큰 차이를 만들 수 있다. 즉, 프록시는 여러 요청을 하나로 일괄 처리하는데 효과적이고, 특히 로드가 많이 발생하는 상황이나 캐싱이 제한된 경우에 매우 유용하게 사용할 수 있다.

#### 2.3. 프록시 + 캐시 사용

프록시와 캐시를 함께 사용한다면, *프록시 앞에 캐시* 를 두는 것이 바람직하다. 마치 '혼잡한 마라톤 경주에서 더 빠른 주자를 먼저 출발시키는 것과 같은 경우'인데, 캐시가 메모리에서 데이터를 제공하기 때문에 동일한 결과에 대한 여러 요청이 들어와도 성능면에서 크게 부담이 없기 때문이다. 

### 3. 인덱스(Indexes)

인덱스를 사용하면 데이터에 빠르게 접근할 수 있다. 일반적으로 데이터베이스에서 주로 사용되며, 빠른 읽기 성능을 충족하기 위해 스토리지 오버헤드와 데이터를 쓰고 인덱스를 업데이트 하기 위한 느린쓰기(slower writes)를 절충하여 사용된다.

![인덱스 구조](http://www.aosabook.org/images/distsys/indexes.jpg)  
*@그림 15: 인덱스 구조*

인덱스는 수많은 데이터에서 작은 데이터 하나를 찾는 경우에 굉장히 유용하다. 특히 물리적으로 분산된 장치에서 해당 데이터가 어디에 있는지 일일이 확인한다는 것은 정말 어려운 일인데, 인덱스를 사용한다면 어떤 서버에 어떤 위치에 존재하는지 관리하기 때문에 굉장히 빠른 속도로 데이터에 접근할 수 있다.
인덱스는 메모리에 저장되거나 혹은 클라이언트로부터 들어오는 요청에 가장 가까운 곳에 저장된다. Berkeley DB 또는 트리와 같은 데이터구조는 데이터를 정렬된 목록에 저장할 때 사용되는데, 이를 인덱스를 활용한 접근방식에 적용하면 굉장히 효과적이다. 혹은 아래의 그림 처럼 원하는 특정 데이터에 접근할 때 까지 위치를 계속해서 이동하는 '지도' 방식으로 인덱스 계층을 만드는 경우도 존재한다. 

![계층 구조를 가지면서 인덱스를 조회하는 경우](http://www.aosabook.org/images/distsys/multipleIndexes.jpg)  
*@그림 16: 계층 구조를 가지면서 인덱스를 조회하는 경우*

혹은 역인덱스(inverse index) 과정을 통해 데이터를 다양하게 쿼리할 수도 있다. 하나의 책에 들어있는 수많은 단어들을 역으로 표현하면 아래 그림처럼 중간 인덱스를 포함한 표현을 만들 수 있을 것이다. 이러한 방법은 이전에 기록된 정보와 연관되어 있지만, 완전히 다른 데이터 결과를 요구할 때 별도의 인덱스를 위한 테이블 없이도 다양한 데이터의 조회와 정렬이 가능함을 보여준다. 즉 더 적은 공간과 비용을 통해 다양한 서비스 제공이 가능하다. 아래는 역인덱스를 활용할 경우의 예시이다.

|**Word(s)**|**Book(s)**|
|---|---|
|being awesome|Book B, Book C, Book D|
|always|Book C, Book F|
|believe|Book B|

이러한 중간 인덱스는 단어 튜플, 데이터 위치 및 발생 횟수와 같이 많은 정보를 담을 수록 더욱 빠르게 합산 가능하다. 그리고 데이터의 섹션을 더욱 작게 만들수록 빅데이터 문제에도 효과적으로 사용될 수 있다. 

### 4. 로드밸런서(Load Balancers)

로드밸런서는 요청 서비스를 담당하는 노드 집합에서 발생하는 로드를 분산하는 역할을 하며, 이를 통해 여러 노드가 시스템에서 동일한 기능을 공정하게 서비스할 수 있게 한다. 로드밸런서의 주요 목적은 많은 동시 연결을 정확하게 처리하고, 이러한 연결을 요청 노드 중 하나로 라우팅하여 시스템이 노드를 추가하여도 더 많은 요청에 대해 정확하게 처리함으로써 서비스의 유연한 확장이 가능하도록 한다.

![로드 밸런서 구조](http://www.aosabook.org/images/distsys/loadBalancer.png)  
*@그림 17: 로드 밸런서 구조*

로드밸런서에는 임의 노드 선택, 라운드로빈, 메모리 또는 CPU 사용률과 같은 특정 기준에 따라 선택하는 등 다양한 알고리즘이 존재한다. 소프트웨어 또는 하드웨어로 구성이 모두 가능한데, 가장 유명한 오픈소스 프로젝트 기반의 로드밸런서는 HAProxy이다.  
분산시스템에서 로드밸런서는 시스템의 맨 앞에 존재하는 경우가 많다. 그러므로 모든 인풋 요청들이 가장 먼저 로드밸런서를 통해 라우팅된다. 아래의 그림과 같이 요청이 여러 로드밸런서로 나누어 라우팅되는 경우도 당연히 존재한다.

![다중 로드 밸런서 구조](http://www.aosabook.org/images/distsys/multipleLoadBalancers.png)  
*@그림 18: 다중 로드 밸런서 구조*

프록시와 유사하게 일부 로드밸런서는 요청 유형에 따른 별개의 라우팅이 가능하도록 설계할 수 있다. 이러한 기술을 또 다른 용어로 *역방향 프록시(reverse proxies)* 라고도 한다.  
로드밸런서는 사용자의 세션별 데이터를 관리할 때에도 사용된다. 전자 상거래 서비스에서 사용자가 쇼핑중에 갑자기 세션을 변경하거나, 다른 노드로 진행 과정이 라우팅되었을 때 장바구니의 내용이 모두 사라진다면? 혹은 내용이 불일치한다면? 이러한 문제를 해결하기 위해 세션을 고정시키고 사용자가 항상 동일한 노드로 라우팅되게 할 수 있을 것이다. 하지만 자동 장애 조치와 같은 부분에 있어서는 고정 노드의 사용이 쾌 위험성있게 다가올 수도 있을 것이다.  
로드밸런서는 기본적으로 비용이 비싸기 때문에, 시스템에 존재하는 노드가 적다면 오히려 라운드로빈 DNS와 같은 시스템을 사용하는 것이 더 적합할 수도 있다. 시스템이 클수록 더욱 정교화된 알고리즘을 사용하는 로드밸런서를 사용하여 트래픽과 요청을 적절하게 분산하고 자동으로 장애를 조치하고, 더 나아가 불량 노드를 알아서 제거해주는 편리한 기능을 사용할 수도 있다. 하지만 이러한 기능들은 문제가 발생하기 전 이를 진단하는 과정을 번거롭게 할 수도 있다. 또한 높은 부하가 발생하는 경우, 로드밸런서는 상대적으로 요청이 많이 몰려 요청 시간이 초과되는 노드를 삭제할 수도 있지만, 그런다고 해서 상황을 좋게 바꾼다고 보장할 수는 없다. 오히려 다른 노드의 부하를 증가시켜 상황을 악화시킬 수도 있다. 그러므로 <u>로드밸런서를 사용할 때에는 모니터링이 굉장히 중요하다</u>.

### 5. 큐(Queues)

큐의 목적은 데이터의 빠른 쓰기 속도에 있다. 시스템이 복잡해질수록 쓰기에 걸리는 시간은 비결정적으로 오래 소요될 수 있다. 이를 해결하기 위해서는 시스템의 쓰기 기능을 비동기적으로 구축해야 하고, 이 때 큐가 사용된다.

![동기식 요청](http://www.aosabook.org/images/distsys/synchronousRequest.png)  
*@그림 19: 동기식 요청*

만약 클라이언트가 요청을 보내고 결과를 받는 서버가 다수 존재한다고 가정하자. 만약 동기식 요청이라고 한다면, 서버가 응답할 수 있는 시간에 비해 너무 많은 요청이 들어올 때 각 클라이언트는 다른 클라이언트의 작업이 완료될 때 까지 대기해야 하는 상황이 발생할 수 있다. 이러한 동기식 요청의 단점은 클라이언트의 성능을 꽤 많이 감소시킨다는 것이다. 클라이언트는 요청에 대한 응답이 올 때 까지 강제적으로 아무것도 할 수 없는 상태로 남게된다. 또한 서버를 아무리 증설하더라도 동기식 요청은 이러한 문제를 해결할 수가 없다. 로드밸런서를 이용해서 작업의 우선순위를 구분하고 공정하게 분배하는 것도 사실상 쉬운 일은 아니다. 결국 이러한 문제를 해결하려면, 클라이언트로부터의 요청과 이를 서비스하기 위해 수행하는 실제 작업 간 추상화 작업이 필요하다.

![큐를 이용한 요청 관리](http://www.aosabook.org/images/distsys/queues.png)  
*@그림 20: 큐를 이용한 요청 관리*

큐를 이용한 요청 관리 방법은 다음과 같다.
1. 작업이 들어오고, 이를 큐에 삽입한다.
2. 작업을 수행할 수 있는 경우에 해당 작업을 선택한다. 작업의 복잡도는 다양할 수 있다.
3. 클라이언트가 작업에 대한 요청을 큐에 제출하면, 결과를 기다리지 않는다. 비동기적으로 동작하고, 대신 요청을 잘 받았다는 승인만 확인한다. 이 때의 승인은 나중에 클라이언트의 요구로 인해 작업 결과를 확인할 수 있는 참조역할을 할 수 있다.  

결국 큐를 이용하면 비동기방식의 동작이 가능하기 때문에, 클라이언트의 요청과 응답을 전략적으로 추상화할 수 있다. 동기 시스템에서의 문제점이었던 요청과 응답의 구분이 불가능한 것과 다르게, 비동기적 시스템에서는 클라이언트가 작업을 요청하고 서비스는 작업이 수신되었음을 확인하는 메시지로 응답함으로써 클라이언트는 작업의 상태를 주기적으로 확인하고 완료된 결과만 수신할 수 있다. 이를 통해 수많은 작업들을 병목현상 없이 처리할 수 있게 되고, 더 나아가 서버에서 발생할 수 있는 다양한 중단 및 장애로부터 서버를 보호할 수도 있다.  
Zookeeper, Redis와 같은 데이터 저장소도 큐를 사용하여 데이터의 입출력을 관리한다.

<br>

## 참고자료
- [Scalable Web Architecture and Distributed Systems - Kate Matsudaira](http://www.aosabook.org/en/distsys.html)
